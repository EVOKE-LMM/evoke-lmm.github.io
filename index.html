
<!DOCTYPE html>
<html lang="en">

<head>
    <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0K19QDCVYV"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0K19QDCVYV');
  </script>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">
  <title>When Large Multimodal Models Confront Evolving Knowledge: Challenges and Pathways</title>
  <meta name="description" content="">
  <meta name="keywords" content="">
  <!-- Favicons -->
  <!-- <link href="assets/img/favicon.png" rel="icon"> -->
  <link href="EVOKE/img/logo.jpg" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

 

  <!-- Fonts -->
  <link href="https://fonts.googleapis.com" rel="preconnect">
  <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&family=Poppins:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&family=Raleway:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Dancing+Script&display=swap" rel="stylesheet">
  <link href='https://fonts.googleapis.com/css?family=Poppins' rel='stylesheet'>
  <link href="https://fonts.googleapis.com/css?family=Montserrat:800|Crimson+Text:italic|Neuton:300" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Poppins:600|IM+Fell+English:italic|Amethysta:regular" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Hind+Madurai:700|IM+Fell+Double+Pica:italic|Ovo:regular" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Raleway:500|Raleway:600|Frank+Ruhl+Libre:300" rel="stylesheet">
  <!-- Vendor CSS Files -->
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">

  <!-- Main CSS File -->
  <link href="assets/css/main.css" rel="stylesheet">
  <link rel="stylesheet" href="http://anijs.github.io/lib/anicollection/anicollection.css">

  <!-- SEO Meta Tags -->
  <title>When Large Multimodal Models Confront Evolving Knowledge: Challenges and Pathways & Large Multimodal Models | Multimodal Evolving Knowledge Injection Benchmark</title>
  <meta name="description" content="">
  <meta name="keywords" content="">
  
  <!-- Open Graph Meta Tags -->
  <meta property="og:title" content="When Large Multimodal Models Confront Evolving Knowledge: Challenges and Pathways">
  <meta property="og:description" content="">
  <!-- <meta property="og:image" content="assets/img/header-logo.png"> -->
  <meta property="og:image" content="EVOKE/img/header-logo.png">
  <meta property="og:url" content="https://evoke-lmm.github.io/">
  <meta property="og:type" content="website">
  
  <!-- Twitter Card Meta Tags -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="When Large Multimodal Models Confront Evolving Knowledge: Challenges and Pathways">
  <meta name="twitter:description" content="">
  <!-- <meta name="twitter:image" content="assets/img/header-logo.png"> -->
  <meta property="og:image" content="EVOKE/img/header-logo.png">

  

  <!-- Additional SEO Meta Tags -->
  <meta name="author" content="EVOKE Research Team">
  <meta name="robots" content="index, follow">
  <link rel="canonical" href="https://evoke-lmm.github.io/">
  
  <!-- Schema.org Markup -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ResearchProject",
    "name": "EVOKE",
    "description": "",
    "url": "https://evoke-lmm.github.io/",
    "keywords": "",
    "author": {
      "@type": "Organization",
      "name": "EVOKE Research Team"
    }
  }
  </script>

  <!-- =======================================================
  * Template Name: Anyar
  * Template URL: https://bootstrapmade.com/anyar-free-multipurpose-one-page-bootstrap-theme/
  * Updated: Aug 07 2024 with Bootstrap v5.3.3
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body class="index-page">

  <header id="header" class="header d-flex align-items-center fixed-top">
    <div class="container position-relative d-flex align-items-center justify-content-between">

      <a class="logo d-flex align-items-center me-auto me-xl-0">
        <!-- Uncomment the line below if you also wish to use an image logo -->
        <!-- <img src="assets/img/logo.png" alt=""> -->
        <!-- <h1 class="sitename">Trust</h1> -->
        <!-- <img src="assets/img/header-logo.png" class="img-fluid" id="logo-img"  alt=""> -->
        <img src="EVOKE/img/header-logo.png" class="img-fluid" id="logo-img"  alt="">

        
      </a>

      <nav id="navmenu" class="navmenu">
        <ul>
          <li><a href="#hero" class="active">Home</a></li>
          <li class="dropdown">
            <a href="#"><span>Explore</span> <i class="bi bi-chevron-down toggle-dropdown"></i></a>
            <ul>
              <li><a href="#about">Background</a></li>
              <li><a href="#evoke">EVOKE Benchmark</a></li>
              <li><a href="#leaderboard">Knowledge Injection Challenge 1</a></li>
              <li><a href="#rules">Evaluation Benchmarks</a></li>
              <li><a href="#forgetting">Knowledge Injection Challenge 2</a></li>
              <li><a href="#pathway1">Knowledge Injection Pathway 1</a></li>
              <li><a href="#pathway2">Knowledge Injection Pathway 2</a></li>
              <li><a href="#ablation">Ablation Experiment</a></li>
              <li><a href="#examples">Qualitative Examples</a></li>
              <li><a href="#team">Team</a></li>
            </ul>
          </li>
          <!-- <li><a href="#about">Background</a></li> -->
          <!-- <li><a href="#dimensions">Dimensions</a></li>
          <li><a href="#models">Models</a></li>
          <li><a href="#leaderboard">Leaderboard</a></li>
          <li><a href="#discussion">Discussion</a></li> -->
          <!-- <li><a href="https://trusteval-docs.readthedocs.io/">Docs</a></li> -->
          <li><a href="EVOKE/slides/When Large Multimodal Models Confront Evolving Knowledge Challenges and Pathways.pdf">Slides</a></li>
          <li><a href="https://github.com/EVOKE-LMM/EVOKE">Github</a></li>
          <li><a href="https://arxiv.org/abs/2505.24449">Paper</a></li>
          <li><a href="https://huggingface.co/datasets/kailinjiang/EVOKE">Dataset</a></li>
          <li><a href="https://huggingface.co/kailinjiang/EVOKE-Models">Models</a></li>


          <!-- <li><a href="#contact">Contact</a></li> -->
        </ul>
        <i class="mobile-nav-toggle d-xl-none bi bi-list"></i>
      </nav>

     <!-- <div class="header-social-links">
       <a href="#" class="twitter"><i class="bi bi-twitter-x"></i></a>
       <a href="#" class="facebook"><i class="bi bi-facebook"></i></a> -->
<!--        <a href="#" class="instagram"><i class="bi bi-instagram"></i></a>-->
<!--        <a href="#" class="linkedin"><i class="bi bi-linkedin"></i></a>-->
  <!-- </div>  -->

    </div>
  </header> 

  <main class="main">

    <!-- Hero Section -->
    <section id="hero" class="hero section">
      <div class="img-background-container"> <!-- 使用 class 而不是 id -->
        <div class="img-background" id="background"></div>
      </div>
      <video autoplay muted  playsinline preload="auto"  id="background-video">
        <!-- <source src="assets/img/background-video - 02-4.mp4" type="video/mp4"> -->
        <source src="EVOKE/video/evoke.mp4" type="video/mp4">
        
        Your browser does not support the video tag.
      </video>

      <div class="container" id="title-container">
        <div class="row justify-content-center">
          <div class="col-lg-7 text-center" data-aos="fade-up" data-aos-delay="100">
            <h2 style="font-size: 48px;"><span>When </span>Large Multimodal Models <span>Confront Evolving Knowledge</span></h2>
            <p style="font-size: 48px;">Challenges and Pathways</p>
          </div>
        </div>
      </div>

    </section><!-- /Hero Section -->

    <section id="about" class="about section">
      <div class="container section-title" data-aos="fade-up">
        <h2>Background</h2>
      </div>

      <div class="container" data-aos="fade-up">


         <p style="font-family: 'Raleway', sans-serif; font-size: 1.5em; text-align: center; font-weight: bold;">
          "The up-to-date events and entities are constantly emerging on the Internet."
        </p>
        <p style="text-align: right; font-family: 'Raleway', sans-serif; font-size: 1.5em; font-weight: bold;">
          – Evolving Knowledge
        </p>


          
        <br>

        <div class="text-center my-3">
          <img src="EVOKE/img/milestone.png" class="img-fluid my-2" alt="" style="width: 100%; height: auto;">
        </div>
        
        <br><br>
        
        <div class="text-center my-3">
          <img src="EVOKE/img/motivation.jpg" class="img-fluid my-2" alt="" style="width: 80%; height: auto;">
        </div>
        
        <div class="row gy-10 my-4">
        <div class="content col-xl-12 d-flex flex-column" data-aos="fade-up" data-aos-delay="100">

      <div class="container section-title" data-aos="fade-up">
        <h2>Introduction</h2>

      </div>

      <p style="font-size: 20px;">Large language/multimodal models (LLMs/LMMs) store extensive pre-trained knowledge but struggle to maintain consistency with real-world updates, making it difficult to avoid catastrophic forgetting while acquiring evolving knowledge. Previous work focused on constructing textual knowledge datasets and exploring knowledge injection in LLMs, lacking exploration of multimodal evolving knowledge injection in LMMs. To address this, we propose the <b>EVOKE</b> benchmark to evaluate LMMs' ability to inject multimodal evolving knowledge in real-world scenarios. Meanwhile, a comprehensive evaluation of multimodal evolving knowledge injection revealed <b>two challenges</b>: <b>(1) Existing knowledge injection methods perform terribly on evolving knowledge.</b> <b>(2) Supervised fine-tuning causes catastrophic forgetting, particularly instruction following ability is severely compromised.</b> Additionally, we provide <span style="font-weight: bold; color: brown;">pathways</span> and find that: <span style="font-weight: bold; color: brown;">(1) Text knowledge augmentation during the training phase improves performance, while image augmentation cannot achieve it.</span> <span style="font-weight: bold; color: brown;">(2) Continual learning methods, especially Replay and MoELoRA, effectively mitigate forgetting.</span> Our findings indicate that current knowledge injection methods have many limitations on evolving knowledge, which motivates further research on more efficient and stable knowledge injection methods.
          </p>

          <video class="img-fluid" controls>
            <source src="EVOKE/video/evoke-video.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          

          
      <div class="row gy-5 my-4" data-aos="fade-up" data-aos-delay="200">
        <div class="col-md-4 icon-box position-relative">
          <img src="EVOKE/img/compliant.png" alt="guideline icon" style="width: 15%;">
          <h4 style="font-size: 22px;">Contribution 1:   Evolving Knowledge Benchmark (EVOKE)</h4>
          
          <ul class="ps-3" style="list-style-type: disc; font-size: 18px;">
            <li>We propose an automated pipeline for collecting evolving knowledge to construct EVOKE.</li>
            <li>A benchmark for evaluating evolving knowledge injection in real-world scenarios.</li>
          </ul>
          </p>

        </div><!-- Icon-Box -->

        <div class="col-md-4 icon-box position-relative">
          <img src="EVOKE/img/framework-1.png" alt="framework icon" style="width: 14%;">
          <h4 style="font-size: 22px;">Contribution 2: Challenges of Evolving Knowledge Injection</h4>
          <ul class="ps-3" style="list-style-type: disc; font-size: 18px;">
            <li>Extensive experiments have been conducted on evolving knowledge injection, revealing two challenges.</li>
            <li>Terrible performance of existing knowledge injection methods and catastrophic forgetting caused by supervised fine-tuning.</li>
        </ul>
        </div><!-- Icon-Box -->

        <div class="col-md-4 icon-box position-relative">
          <img src="EVOKE/img/research.png" alt="analysis icon" style="width: 14%;">
          <h4 style="font-size: 22px;">Contribution 3: Pathways of Evolving Knowledge Injection</h4>
          <ul class="ps-3" style="list-style-type: disc; font-size: 18px;">
            <li>We provide the pathways and demonstrate that text knowledge augmentation during the training phase improves performance.</li>
            <li>And continual learning methods effectively mitigate forgetting.</li>
        </ul>

        </div><!-- Icon-Box -->
      </div>
    <!-- </section> -->



    <section id="evoke" class="models section">

      <!-- Section Title -->
      <div class="container section-title" data-aos="fade-up">
        <!-- <h2>Dynamic Benchmark</h2> -->
        <h2><b>EVO</b>lving <b>K</b>nowledg<b>E</b> Benchmark </h2>

      </div><!-- End Section Title -->
      <div class="row justify-content-center" data-aos="fade-up">

        <div class="col-11">
          <p style="font-size: 20px;">The EVOKE benchmark comprises </span> <span style="font-weight: bold; color: brown;">9,422</span> knowledge-image pairs for LMM knowledge injection, spanning 159 fine-grained types (29 New types and 130 Entity types).</p>

          <div class="text-center my-3">
            <img src="EVOKE/img/data_display.png" class="img-fluid my-2" alt="" style="width: 100%; height: auto;">
          </div>
        
          <br><br> 

          <p style="font-size: 20px;">Overall pipeline of the construction for EVOKE benchmark. </span> <span style="font-weight: bold; color: brown;">(a) Firstly</span>, collect original data from CNN and Wikipedia, and filter popular data. </span> <span style="font-weight: bold; color: brown;">(b) Secondly</span>, we use GPT-4o to summarize the textual content of the original data. </span> <span style="font-weight: bold; color: brown;">(c) Subsequently</span>, QA pairs are generated by GPT-4o and query images are downloaded from Google. </span> <span style="font-weight: bold; color: brown;">(d) Lastly</span>, we manually review the original knowledge image and query image. The source of heuristic query: we manually write multiple templates and randomly select one template for each piece of data.</p>
          
          <div class="text-center my-3">
            <img src="EVOKE/img/data_construction.png" class="img-fluid my-2" alt="" style="width: 100%; height: auto;">
          </div>
        </div>

        

    </section>
        


     <section id="leaderboard" class="leaderboard section">
      <div class="container section-title" data-aos="fade-up">
        <h2>Knowledge Injection Challenge 1: Terrible Performance</h2>
      </div>
      <div class="container" data-aos="fade-up">
        <div class="row gy-4">
          <div class="container mt-5">
            <div class="row">
              <!-- 左侧图片 -->
              <div class="col-xl-5 text-center">
                <img src="EVOKE/img/table1.png" alt="Image 1" class="img-fluid" style="max-width: 100%; height: auto;" />
              </div>
    
              <!-- 右侧 Accordion 内容 -->
              <div class="col-xl-7" data-aos="fade-up" data-aos-delay="200">
                <div class="row gy-4">
                  <div class="col-12">
                    <div class="accordion" id="trustModelRules">
                      <div class="accordion-item">
                        <h2 class="accordion-header" id="headingOne">
                          <button class="accordion-button" type="button" data-bs-toggle="collapse" data-bs-target="#collapseOne" aria-expanded="true" aria-controls="collapseOne" data-bs-parent="#trustModelRules">
                            Findings 1: The non-zero performance of Vanilla.
                          </button>
                        </h2>
                        <div id="collapseOne" class="accordion-collapse collapse show" aria-labelledby="headingOne" data-bs-parent="#trustModelRules">
                          <div class="accordion-body">
                            This findings indicates that although there is no explicit exposure to query related knowledge during LMM training, model has the ability to leverage existing knowledge for reasonable inference in question answering.
                          </div>
                        </div>
                      </div>
    
                      <div class="accordion-item">
                        <h2 class="accordion-header" id="headingTwo">
                          <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseTwo" aria-expanded="false" aria-controls="collapseTwo" data-bs-parent="#trustModelRules">
                            Findings 2: No one knowledge injection method performs exceptionally well.
                          </button>
                        </h2>
                        <div id="collapseTwo" class="accordion-collapse collapse" aria-labelledby="headingTwo" data-bs-parent="#trustModelRules">
                          <div class="accordion-body">
                            Experimental results indicate that none of the evaluated approaches demonstrate superior effectiveness in multimodal evolving knowledge injection tasks. The best-performing method, LLaVA's MM-RAG-Gloden Context, achieves only 56.13 in accuracy score, which falls short of expectations. Notably, some methods is extremely poor, for example, Qwen-VL-Chat's LoRA only has a accuracy 1.11 higher than Vanilla. These findings underscore the significant potential for advancement in the field of evolving knowledge injection.
                          </div>
                        </div>
                      </div>
    
                      <div class="accordion-item">
                        <h2 class="accordion-header" id="headingThree">
                          <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseThree" aria-expanded="false" aria-controls="collapseThree" data-bs-parent="#trustModelRules">
                            Findings 3: MM-RAG outperforms SFT in overall performance, particularly in cross-modal retrieval.
                          </button>
                        </h2>
                        <div id="collapseThree" class="accordion-collapse collapse" aria-labelledby="headingThree" data-bs-parent="#trustModelRules">
                          <div class="accordion-body">
                            As shown in Table1, MM-RAG performs well on the LLaVA-v1.5 and Qwen-VL-Chat without updating LLM parameters, avoiding potential side effects. Additionally, the results for Text-Only and Image-Only are similar but both are significantly lower than UniIR.
                          </div>
                        </div>
                      </div>
    
                      <div class="accordion-item">
                        <h2 class="accordion-header" id="headingFour">
                          <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseFour" aria-expanded="false" aria-controls="collapseFour" data-bs-parent="#trustModelRules">
                            Findings 4: Internet Augmented Generation can help LMMs adapt to evolving knowledge.
                          </button>
                        </h2>
                        <div id="collapseFour" class="accordion-collapse collapse" aria-labelledby="headingFour" data-bs-parent="#trustModelRules">
                          <div class="accordion-body">
                            By observation, Perplexity AI outperforms Gemini and approaches the Gloden Context'performance of the Qwen-VL-Chat. This highlights the internet retrieval capabilities of commercial LMMs. IAG methods independently retrieve critical information from the Internet without relying on external injection data, serving as input for model reasoning. They achieve goodish performance without side effects, motivating further research on more efficient IAG methods.
                          </div>
                        </div>
                      </div>
    
                      <!-- 继续添加更多的 accordion 项目，如需要 -->
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
      <br><br>
      <h2 style="font-size: 1.5rem; font-weight: bold; text-align: center;">Knowledge Injection Performance on Fine-grained Types</h2>
      <div class="container" data-aos="fade-up">
        <div class="row gy-4">
          <div class="container mt-5 text-center">
            <img src="EVOKE/img/table5.png" alt="Image 1" class="img-fluid" style="max-width: 100%; height: auto;" />
          </div>
        </div>
      </div>
    </section>
    
    <!-- 引入 Bootstrap 的 JavaScript -->
    <!-- <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/js/bootstrap.bundle.min.js"></script> -->
    
    



<!-- Rules Section -->


<section id="rules" class="rules section">
  <div class="container">
    <div class="row gy-5">
      <div class="content col-xl-5 d-flex flex-column" data-aos="fade-up" data-aos-delay="100">
        <div class="container section-title" data-aos="fade-up">
          <h2>LMM's previous capability evaluation benchmarks</h2>
        </div>
        <p style="font-size: 20px;" class="rules-intro"> 
          To systematically evaluate the side effect of knowledge injection on the general capabilities of LMMs, we conduct comprehensive assessments using 12 benchmark datasets spanning 7 distinct capability dimensions:
        </p>
        <ul class="list-unstyled">
          <li style="margin-top: 10pt; margin-bottom: 10pt;"><i class="bi bi-check-circle text-primary me-2"></i>Comprehensive Evaluation</li>
          <li style="margin-top: 10pt; margin-bottom: 10pt;"><i class="bi bi-check-circle text-primary me-2"></i>Optical Character Recognition</li>
          <li style="margin-top: 10pt; margin-bottom: 10pt;"><i class="bi bi-check-circle text-primary me-2"></i>Multidisciplinary</li>
          <li style="margin-top: 10pt; margin-bottom: 10pt;"><i class="bi bi-check-circle text-primary me-2"></i>Instruction Following</li>
          <li style="margin-top: 10pt; margin-bottom: 10pt;"><i class="bi bi-check-circle text-primary me-2"></i>Multi-Round QA</li>
          <li style="margin-top: 10pt; margin-bottom: 10pt;"><i class="bi bi-check-circle text-primary me-2"></i>Mathematical Reasoning</li>
          <li style="margin-top: 10pt; margin-bottom: 10pt;"><i class="bi bi-check-circle text-primary me-2"></i>Hallucination</li>
        </ul>
      </div>

      <div class="col-xl-7" data-aos="fade-up" data-aos-delay="200">
        <div class="row gy-4">
          <div class="col-12">
            <div class="accordion" id="capabilityAccordion">
              <!-- Dimension 1 -->
              <div class="accordion-item">
                <h2 class="accordion-header" id="dimension1Header">
                  <button class="accordion-button" type="button" data-bs-toggle="collapse" 
                    data-bs-target="#dimension1Content" aria-expanded="true" 
                    aria-controls="dimension1Content">
                    Capability Dimension 1: Comprehensive Evaluation (MME and MMBench)
                  </button>
                </h2>
                <div id="dimension1Content" class="accordion-collapse collapse show" 
                  aria-labelledby="dimension1Header" data-bs-parent="#capabilityAccordion">
                  <div class="accordion-body">
                    <b>MME</b> is a comprehensive evaluation benchmark designed to assess the performance of LMMs across 14 distinct tasks, encompassing both perception and cognition abilities. To ensure fair and accurate comparisons, MME provides concise, manually designed instruction-answer pairs, eliminating the need for extensive prompt engineering.
                    <br><br>
                    <b>MMBench</b> is a bilingual benchmark designed to evaluate the comprehensive capabilities of LMMs across multiple modalities. It offers a meticulously curated dataset with over 3,000 multiple-choice questions covering 20 distinct ability dimensions, such as object localization and social reasoning. Additionally, MMBench provides questions in both English and Chinese, enabling comparative evaluations of LMM performance across these languages.
                  </div>
                </div>
              </div>

              <!-- Dimension 2 -->
              <div class="accordion-item">
                <h2 class="accordion-header" id="dimension2Header">
                  <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" 
                    data-bs-target="#dimension2Content" aria-expanded="false" 
                    aria-controls="dimension2Content">
                    Capability Dimension 2: Optical Character Recognition (SEEDBench2_Plus and OCRBench)
                  </button>
                </h2>
                <div id="dimension2Content" class="accordion-collapse collapse" 
                  aria-labelledby="dimension2Header" data-bs-parent="#capabilityAccordion">
                  <div class="accordion-body">
                    <b>SEED-Bench-2-Plus</b> is a comprehensive benchmark designed to evaluate the performance of LMMs in understanding text-rich visual content, such as charts, maps, and web pages. It consists of 2,300 multiple-choice questions spanning three broad categories: Charts, Maps, and Webs, each covering a wide range of real-world scenarios where text and visual elements are intertwined. The benchmark aims to address the gap in evaluating LMMs' ability to comprehend and reason about visual data that contains significant textual information, which is crucial for practical applications like document analysis, navigation, and web content understanding.
                    <br><br>
                    <b>OCRBench</b> is a comprehensive evaluation benchmark designed to assess the OCR capabilities of LMMs. It encompasses 29 datasets across five key tasks: Text Recognition, Scene Text-Centric VQA, Document-Oriented VQA, Key Information Extraction (KIE), and Handwritten Mathematical Expression Recognition (HMER). The benchmark aims to provide a thorough assessment of LMMs' performance in various text-related visual tasks, highlighting their strengths and weaknesses, particularly in handling multilingual text, handwritten text, non-semantic text, and mathematical expressions.
                  </div>
                </div>
              </div>

              <!-- Dimension 3 -->
              <div class="accordion-item">
                <h2 class="accordion-header" id="dimension3Header">
                  <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" 
                    data-bs-target="#dimension3Content" aria-expanded="false" 
                    aria-controls="dimension3Content">
                    Capability Dimension 3: Multidisciplinary (ScienceQA and MMMU)
                  </button>
                </h2>
                <div id="dimension3Content" class="accordion-collapse collapse" 
                  aria-labelledby="dimension3Header" data-bs-parent="#capabilityAccordion">
                  <div class="accordion-body">
                    <b>MMMU</b> is a comprehensive benchmark designed to evaluate LMMs on tasks that require college-level subject knowledge and deliberate reasoning. It comprises 11,500 meticulously curated multimodal questions sourced from college exams, quizzes, and textbooks, spanning six core disciplines: Art & Design, Business, Science, Health & Medicine, Humanities & Social Science, and Technology & Engineering. These questions cover 30 subjects and 183 subfields, featuring 30 diverse image types such as charts, diagrams, maps, tables, music sheets, and chemical structures.
                    <br><br>
                    <b>ScienceQA</b> is a benchmark designed to evaluate AI models' abilities in scientific question answering. It includes multiple-choice and free-response questions across core subjects like Mathematics, Physics, Chemistry, and Biology. The benchmark provides knowledge points and detailed explanations for each problem, facilitating comprehensive assessment of reasoning capabilities.
                  </div>
                </div>
              </div>

              <!-- Dimension 4 -->
              <div class="accordion-item">
                <h2 class="accordion-header" id="dimension4Header">
                  <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" 
                    data-bs-target="#dimension4Content" aria-expanded="false" 
                    aria-controls="dimension4Content">
                    Capability Dimension 4: Instruction Following (MIA-Bench)
                  </button>
                </h2>
                <div id="dimension4Content" class="accordion-collapse collapse" 
                  aria-labelledby="dimension4Header" data-bs-parent="#capabilityAccordion">
                  <div class="accordion-body">
                    <b>MIA-Bench</b> is a benchmark designed to evaluate the ability of LMMs to adhere strictly to complex instructions. It comprises a diverse set of 400 image-prompt pairs, each crafted to challenge models' compliance with layered instructions, requiring accurate and contextually
                  </div>
                </div>
              </div>

              <!-- Dimension 5 -->
              <div class="accordion-item">
                <h2 class="accordion-header" id="dimension5Header">
                  <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" 
                    data-bs-target="#dimension5Content" aria-expanded="false" 
                    aria-controls="dimension5Content">
                    Capability Dimension 5: Multi-Round QA (MMDU)
                  </button>
                </h2>
                <div id="dimension5Content" class="accordion-collapse collapse" 
                  aria-labelledby="dimension5Header" data-bs-parent="#capabilityAccordion">
                  <div class="accordion-body">
                    <b>MMDU</b> is a comprehensive evaluation framework designed to assess the capabilities of LMMs in handling multi-turn, multi-image dialog scenarios. It focuses on understanding complex interactions involving multiple images and sequential dialog turns, which are critical for real-world applications like visual storytelling, medical diagnosis, and interactive AI systems. The benchmark includes a diverse dataset with rich annotations, enabling models to be fine-tuned and evaluated on tasks requiring contextual reasoning, image-text alignment, and temporal coherence.
                  </div>
                </div>
              </div>

              <!-- Dimension 6 -->
              <div class="accordion-item">
                <h2 class="accordion-header" id="dimension6Header">
                  <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" 
                    data-bs-target="#dimension6Content" aria-expanded="false" 
                    aria-controls="dimension6Content">
                    Capability Dimension 6: Mathematical Reasoning (MathVista and Math-Vision)
                  </button>
                </h2>
                <div id="dimension6Content" class="accordion-collapse collapse" 
                  aria-labelledby="dimension6Header" data-bs-parent="#capabilityAccordion">
                  <div class="accordion-body">
                    <b>MathVista</b> is a benchmark designed to evaluate the mathematical reasoning capabilities of foundation models within visual contexts. It comprises 6,141 examples drawn from 28 existing multimodal datasets and introduces three new datasets: IQTest, FunctionQA, and PaperQA. These tasks require models to perform fine-grained visual understanding and compositional reasoning.
                    <br><br>
                    <b>Math-Vision</b> is a meticulously curated dataset comprising 3,040 high-quality mathematical problems, each embedded within a visual context and sourced from real mathematics competitions. This benchmark spans 16 distinct mathematical disciplines and is organized across five levels of difficulty, offering a comprehensive platform to evaluate the mathematical reasoning abilities of LMMs.
                  </div>
                </div>
              </div>

              <!-- Dimension 7 -->
              <div class="accordion-item">
                <h2 class="accordion-header" id="dimension7Header">
                  <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" 
                    data-bs-target="#dimension7Content" aria-expanded="false" 
                    aria-controls="dimension7Content">
                    Capability Dimension 7: Hallucination (POPE and HallusionBench)
                  </button>
                </h2>
                <div id="dimension7Content" class="accordion-collapse collapse" 
                  aria-labelledby="dimension7Header" data-bs-parent="#capabilityAccordion">
                  <div class="accordion-body">
                    <b>POPE</b> is a benchmark designed to systematically assess object hallucination in LMMs. Object hallucination refers to the tendency of these models to generate descriptions containing objects not present in the corresponding images. POPE addresses this issue by implementing a polling-based query method that evaluates models' accuracy in identifying the existence of specific objects within images. This approach provides a more stable and flexible evaluation of object hallucination, revealing that current LMMs often generate objects inconsistent with the target images.
                    <br><br>
                    <b>HallusionBench</b> is a comprehensive benchmark designed to evaluate LMMs on their ability to accurately interpret and reason about visual data, specifically addressing issues of language hallucination and visual illusion. It comprises 346 images paired with 1,129 questions among visual dependent and visual supplement. The benchmark introduces a novel structure for visual questions, enabling quantitative analysis of models' response tendencies, logical consistency, and various failure modes.
                  </div>
                </div>
              </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



    <section id="forgetting" class="forgetting section">
      <div class="container section-title" data-aos="fade-up">
        <h2>Knowledge Injection Challenge 2: Catastrophic Forgetting</h2>
      </div>
      
      <div class="container" data-aos="fade-up">
        <div class="row gy-4">
          <div class="container mt-5">
              <tr>
                <td><img src="EVOKE/img/table2.png" alt="Image 1" class="img-fluid" /></td>
              </tr>
          </div>
      </div>
    </section>


    <section id="pathway1" class="pathway1 section">
      <div class="container section-title" data-aos="fade-up">
        <h2>Knowledge Injection Pathway 1: Knowledge Augmentation</h2>
      </div>
    
      <div class="container" data-aos="fade-up">
        <div class="row gy-4">
          <div class="container mt-5">
            <div class="row"> 
              <div class="col-6 text-center">
                <img src="EVOKE/img/text.png" alt="Image 1" class="img-fluid" />
              </div>
              <div class="col-6 text-center">
                <img src="EVOKE/img/image_aug.png" alt="Image 2" class="img-fluid" />
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>
    



    <section id="pathway2" class="pathway2 section">
      <div class="container section-title" data-aos="fade-up">
        <h2>Knowledge Injection Pathway 2: Continual Learning</h2>
      </div>

      <div class="container" data-aos="fade-up">
        <div class="row gy-4">
          <div class="container mt-5">
            <div class="row">
              <div class="col-6 text-center">
                <img src="EVOKE/img/replay.png" alt="Image 1" class="img-fluid" />
              </div>
              <div class="col-6 text-center">
                <img src="EVOKE/img/table3.png" alt="Image 2" class="img-fluid" />
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>
    



    <section id="ablation" class="ablation section">
      <div class="container section-title" data-aos="fade-up">
        <h2>Ablation Experiment</h2>
      </div>

      <h2 style="font-size: 1.5rem; font-weight: bold; text-align: center;">Sequential Fine-Tuning</h2>
      <div class="container" data-aos="fade-up">
        <div class="row gy-4">
          <div class="container mt-5">
            <tr>
              <td><img src="EVOKE/img/sft_all.png" alt="Image 1" class="img-fluid" /></td>
              <br><br> 
              <td><img src="EVOKE/img/sft_ft.png" alt="Image 1" class="img-fluid" /></td>
              <br><br> 
              <td><img src="EVOKE/img/sft_lora.png" alt="Image 1" class="img-fluid" /></td>
            </tr>
          </div>
        </div>
      </div>
      <br><br> 
      <h2 style="font-size: 1.5rem; font-weight: bold; text-align: center;">MM-RAG</h2>

      <div class="container" data-aos="fade-up">
        <div class="row gy-4">
          <div class="container mt-5">
            <tr>
              <td><img src="EVOKE/img/rag.png" alt="Image 1" class="img-fluid" /></td>
            </tr>
          </div>
        </div>
      </div>
    </section>
    



    <section id="examples" class="examples section">
      <div class="container section-title" data-aos="fade-up">
        <h2>Qualitative Examples</h2>
      </div>
    
      <div class="container" data-aos="fade-up">
        <div class="row gy-4">
          <div class="container mt-5">
            <!-- Bootstrap Carousel -->
            <div id="carouselExampleAutoplaying" class="carousel slide" data-bs-ride="carousel" data-bs-interval="4000">
              <div class="carousel-inner">
                <!-- 第一张图片 -->
                <div class="carousel-item active">
                  <img src="EVOKE/img/example1.jpg" alt="Image 1" class="d-block w-100 img-fluid" />
                </div>
                <!-- 第二张图片 -->
                <div class="carousel-item">
                  <img src="EVOKE/img/example2.jpg" alt="Image 2" class="d-block w-100 img-fluid" />
                </div>
                <!-- 第三张图片 -->
                <div class="carousel-item">
                  <img src="EVOKE/img/example3.jpg" alt="Image 3" class="d-block w-100 img-fluid" />
                </div>
                <!-- 第四张图片 -->
                <div class="carousel-item">
                  <img src="EVOKE/img/example4.jpg" alt="Image 4" class="d-block w-100 img-fluid" />
                </div>
              </div>
              <!-- 控制按钮 -->
              <button class="carousel-control-prev" type="button" data-bs-target="#carouselExampleAutoplaying" data-bs-slide="prev">
                <span class="carousel-control-prev-icon" aria-hidden="true"></span>
                <span class="visually-hidden">Previous</span>
              </button>
              <button class="carousel-control-next" type="button" data-bs-target="#carouselExampleAutoplaying" data-bs-slide="next">
                <span class="carousel-control-next-icon" aria-hidden="true"></span>
                <span class="visually-hidden">Next</span>
              </button>
            </div>
          </div>
        </div>
      </div>

      <style>
        .carousel {
          height: 800px;
          margin-bottom: 30px;
        }

        .carousel-inner {
          height: 100%;
        }

        .carousel-item {
          height: 100%;
        }

        .carousel-item img {
          height: 100%;
          object-fit: contain;
          background-color: #f8f9fa;
        }

        .carousel-control-prev,
        .carousel-control-next {
          height: 100%;
        }

        /* 增加箭头大小 */
        .carousel-control-prev-icon,
        .carousel-control-next-icon {
          width: 40px;
          height: 40px;
        }

        .carousel-control-prev,
        .carousel-control-next {
          width: 10%;
        }

        .carousel-caption {
          font-size: 1.5rem;
          font-weight: 500;
        }
      </style>
    </section>
    
    <!-- 引入 Bootstrap 的 JavaScript -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/js/bootstrap.bundle.min.js"></script>
    
    

 


    
    <!-- Team Section -->
    <section id="team" class="team section">

      <div class="container section-title" data-aos="fade-up">
        <h2>Our Team</h2>
      </div>
      <div class="container">
        <div class="team-avatars">
          <a href="https://kailinjiang.github.io/" class="avatar-link">
            <div class="avatar-circle">
              <img src="EVOKE/author/jkl2.png" alt="Person 1">
            </div>
            <div class="avatar-name">Kailin Jiang</div>
            <div class="avatar-info">USTC & BIGAI</div>
          </a>
          <a href="https://yuntaodu.github.io/" class="avatar-link">
            <div class="avatar-circle">
              <img src="EVOKE/author/duyuntao.png" alt="Person 2">
            </div>
            <div class="avatar-name">Yuntao Du</div>
            <div class="avatar-info">SDU</div>
          </a>
          <a href="" class="avatar-link">
            <div class="avatar-circle">
              <img src="EVOKE/author/dingyukai.png" alt="Person 3">
            </div>
            <div class="avatar-name">Yukai Ding</div>
            <div class="avatar-info">WUH & BIGAI</div>
          </a>
          <a href="" class="avatar-link">
            <div class="avatar-circle">
              <img src="EVOKE/author/renyucheng.png" alt="Person 4">
            </div>
            <div class="avatar-name">Yucheng Ren</div>
            <div class="avatar-info">USYD</div>
          </a>
          <a href="https://flocrystal.github.io/" class="avatar-link">
            <div class="avatar-circle">
              <img src="EVOKE/author/jiangning.png" alt="Person 5">
            </div>
            <div class="avatar-name">Ning Jiang</div>
            <div class="avatar-info">NEFU</div>
          </a>
          <a href="https://zhigao2017.github.io/" class="avatar-link">
            <div class="avatar-circle">
              <img src="EVOKE/author/gaozhi.png" alt="Person 6">
            </div>
            <div class="avatar-name">Zhi Gao</div>
            <div class="avatar-info">PKU & BIGAI</div>
          </a>
          <a href="https://zilongzheng.github.io/" class="avatar-link">
            <div class="avatar-circle">
              <img src="EVOKE/author/zhengzilong.png" alt="Person 7">
            </div>
            <div class="avatar-name">Zilong Zheng</div>
            <div class="avatar-info">BIGAI</div>
          </a>
          <a href="https://faculty.ustc.edu.cn/liulei13/zh_CN/index.htm" class="avatar-link">
            <div class="avatar-circle">
              <img src="EVOKE/author/liulei.png" alt="Person 8">
            </div>
            <div class="avatar-name">Lei Liu</div>
            <div class="avatar-info">USTC</div>
          </a>
          <a href="http://staff.ustc.edu.cn/~binli/" class="avatar-link">
            <div class="avatar-circle">
              <img src="EVOKE/author/libin.png" alt="Person 9">
            </div>
            <div class="avatar-name">Bin Li</div>
            <div class="avatar-info">USTC</div>
          </a>
          <a href="https://liqing.io/" class="avatar-link">
            <div class="avatar-circle">
              <img src="EVOKE/author/liqing.png" alt="Person 10">
            </div>
            <div class="avatar-name">Qing Li</div>
            <div class="avatar-info">BIGAI</div>
          </a>
        </div>
      </div>

      <style>
        .team-avatars {
          display: flex;
          flex-wrap: nowrap;
          justify-content: center;
          gap: 8px;
          padding: 20px;
          width: 100%;
          height: 200px; /* 添加固定高度，确保足够容纳头像和文字 */
        }

        .avatar-link {
          text-decoration: none;
          transition: transform 0.3s ease;
          display: flex;
          flex-direction: column;
          align-items: center;
          color: inherit;
          height: 100%; /* 确保链接占满容器高度 */
        }

        .avatar-link:hover {
          transform: scale(1.1);
        }

        .avatar-circle {
          width: 122px;
          height: 122px;
          border-radius: 50%;
          overflow: hidden;
          border: 3px solid #fff;
          box-shadow: 0 2px 10px rgba(0,0,0,0.1);
          flex-shrink: 0; /* 防止头像被压缩 */
        }

        .avatar-circle img {
          width: 100%;
          height: 100%;
          object-fit: cover;
        }

        .avatar-name {
          font-size: 14px;
          text-align: center;
          color: #333;
          margin-top: 8px;
          font-weight: 500;
          height: 20px; /* 固定名字高度 */
          line-height: 20px; /* 确保文字垂直居中 */
        }

        .avatar-info {
          font-size: 12px;
          text-align: center;
          color: #666;
          margin-top: 4px;
          height: 16px; /* 固定信息高度 */
          line-height: 16px; /* 确保文字垂直居中 */
        }
      </style>

    </section><!-- /Clients Section -->

    <div class="container section-title" data-aos="fade-up">
      <h2>BibTeX</h2>
    </div>
  <!-- 新增 BibTeX 栏目 -->



<div class="team-bibtex" style="max-width: 950px; margin: 32px auto 50px auto; background: #f8f9fa; border-radius: 10px; box-shadow: 0 2px 8px rgba(0,0,0,0.05); padding: 20px; position: relative;">
  <!-- Copy按钮 -->
  <button id="copy-bibtex" style="position: absolute; top: 15px; right: 15px; background: #6B46C1; color: white; border: 1px solid #8B5CF6; border-radius: 6px; padding: 8px 12px; font-size: 12px; cursor: pointer; display: flex; align-items: center; gap: 5px; transition: background-color 0.3s;">
    <svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
      <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
      <path d="m5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
    </svg>
    Copy
  </button>
  
  <!-- 代码容器 -->
  <div style="background: white; border-radius: 6px; padding: 20px; margin-top: 40px; overflow-x: auto; border: 1px solid #e5e7eb;">
    <pre id="bibtex-content" style="font-size: 14px; color: #333; background: none; border: none; margin: 0; padding: 0; font-family: 'Fira Mono', 'Consolas', 'Menlo', monospace; white-space: pre; word-break: normal; min-width: max-content;">@article{jiang2025evoke,
  title = {When Large Multimodal Models Confront Evolving Knowledge:Challenges and Pathways},
  author = {Kailin Jiang and Yuntao Du and Yukai Ding and Yuchen Ren and Ning Jiang and Zhi Gao and Zilong Zheng and Lei Liu and Bin Li and Qing Li},
  year = {2025}
}
}</pre>
  </div>
</div>

<script>
document.addEventListener('DOMContentLoaded', function() {
  const copyButton = document.getElementById('copy-bibtex');
  const bibtexContent = document.getElementById('bibtex-content');
  
  copyButton.addEventListener('click', async function() {
    try {
      await navigator.clipboard.writeText(bibtexContent.textContent);
      
      // 临时改变按钮文本和样式
      const originalText = copyButton.innerHTML;
      copyButton.innerHTML = '<svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><polyline points="20,6 9,17 4,12"></polyline></svg>Copied!';
      copyButton.style.background = '#059652';
      
      // 2秒后恢复原状
      setTimeout(() => {
        copyButton.innerHTML = originalText;
        copyButton.style.background = '#6B46C1';
      }, 2000);
      
    } catch (err) {
      console.error('复制失败:', err);
      // 降级方案：选中文本
      const range = document.createRange();
      range.selectNode(bibtexContent);
      window.getSelection().removeAllRanges();
      window.getSelection().addRange(range);
      
      try {
        document.execCommand('copy');
        copyButton.innerHTML = 'Copied!';
        setTimeout(() => {
          copyButton.innerHTML = 'Copy';
        }, 2000);
      } catch (fallbackErr) {
        alert('复制失败，请手动选择文本复制');
      }
    }
  });
  
  // 按钮悬停效果
  copyButton.addEventListener('mouseenter', function() {
    this.style.background = '#8B5CF6';
  });
  
  copyButton.addEventListener('mouseleave', function() {
    if (this.style.background !== '#059652') {
      this.style.background = '#6B46C1';
    }
  });
});
</script>















            

    <!-- booktitle={The Thirteenth International Conference on Learning Representations}, -->

  </main>

  <footer id="footer" class="footer dark-background">

    

    <div class="container footer-top">
      <div class="row gy-4">
        <div class="col-lg-6 col-md-6 footer-about">
          <a href="index.html" class="d-flex align-items-center">
            <span class="sitename">EVOlving KnowledgE</span>
          </a>
          <div class="footer-contact pt-3">
            <!-- General Email Section -->
            <p style="font-size: 20px;"><strong>General Email:</strong></p>
            <p style="font-size: 20px;"><span>Kailin Jiang: 
                      <br>
                      <span style="color: #ffe066; font-weight: bold;">jiangkailin@bigai.ai</span>
                      <br>
                      <span style="color: #ffe066; font-weight: bold;">kailinjiang@mail.ustc.edu.cn</span>
                    </span></p>

          </div>
        </div>

        <div class="col-lg-2 col-md-3 footer-links">
          <h4 style="font-size: 20px;">Useful Links</h4>
          <ul style="font-size: 16px;">
            <li><i class="bi bi-chevron-right"></i> <a href="https://evoke-lmm.github.io/">Home</a></li>
            <li><i class="bi bi-chevron-right"></i> <a href="https://arxiv.org/abs/2505.24449">Paper</a></li>
            <li><i class="bi bi-chevron-right"></i> <a href="EVOKE/slides/When Large Multimodal Models Confront Evolving Knowledge Challenges and Pathways.pdf">Slides</a></li>
            <li><i class="bi bi-chevron-right"></i> <a href="https://github.com/EVOKE-LMM/EVOKE">Github</a></li>
            <li><i class="bi bi-chevron-right"></i> <a href="https://huggingface.co/datasets/kailinjiang/EVOKE">Dataset</a></li>
            <li><i class="bi bi-chevron-right"></i> <a href="https://huggingface.co/kailinjiang/EVOKE-Models">Models</a></li>
          </ul>
        </div>
      </div>
    </div>

    <div class="container copyright text-center mt-4">
      <p>© <span>Copyright</span> <strong class="px-1 sitename">EVOlving KnowledgE</strong> <span>All Rights Reserved</span></p>
      <div class="credits">
      </div>
    </div>

  </footer>

  <!-- Scroll Top -->
  <a href="#" id="scroll-top" class="scroll-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Preloader -->
  <div id="preloader"></div>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>
  <script src="assets/vendor/aos/aos.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/imagesloaded/imagesloaded.pkgd.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>

  <!-- Main JS File -->
  <script src="assets/js/main.js"></script>
  <script src="assets/js/table2.js"></script>
  <script src="assets/js/anime.js"></script>
  <script src="anime.min.js"></script>
   <!-- 使用官方 CDN -->
  <!-- <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js"></script> -->



</body>




</html>
